{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee58d047",
   "metadata": {},
   "source": [
    "# üèÅ Quick Start: EfficientNet Fine-tuning on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d2c64d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd5d8c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "data_root = Path(\"../../../data/out_data_split\")\n",
    "train_dir = data_root / \"train\"\n",
    "val_dir = data_root / \"val\"\n",
    "batch_size = 32\n",
    "num_epochs = 20  # Keep it short for first run\n",
    "learning_rate = 1e-4\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d5f0e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['4011', '4015', '4088', '4196', '7020097009819', '7020097026113', '7023026089401', '7035620058776', '7037203626563', '7037206100022', '7038010009457', '7038010013966', '7038010021145', '7038010054488', '7038010068980', '7039610000318', '7040513000022', '7040513001753', '7040913336684', '7044610874661', '7048840205868', '7071688004713', '7622210410337', '90433917', '90433924', '94011']\n"
     ]
    }
   ],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(str(train_dir), transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(str(val_dir), transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "print(f\"Classes: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aa075d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model(\"efficientnet_b0\", pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier\n",
    "model.classifier = nn.Linear(model.classifier.in_features, len(class_names))\n",
    "\n",
    "# Only train classifier\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b2160726",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        correct += (out.argmax(1) == y).sum().item()\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n",
    "\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            total_loss += loss.item()\n",
    "            correct += (out.argmax(1) == y).sum().item()\n",
    "    return total_loss / len(loader), correct / len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38000e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Acc: 0.1499, Val Acc: 0.3697\n",
      "Current learning rate: 0.000100\n",
      "Epoch 2/20 - Train Acc: 0.3906, Val Acc: 0.5530\n",
      "Current learning rate: 0.000100\n",
      "Epoch 3/20 - Train Acc: 0.5077, Val Acc: 0.6500\n",
      "Current learning rate: 0.000100\n",
      "Epoch 4/20 - Train Acc: 0.5850, Val Acc: 0.6985\n",
      "Current learning rate: 0.000100\n",
      "Epoch 5/20 - Train Acc: 0.6476, Val Acc: 0.7561\n",
      "Current learning rate: 0.000100\n",
      "Epoch 6/20 - Train Acc: 0.6789, Val Acc: 0.7758\n",
      "Current learning rate: 0.000050\n",
      "Epoch 7/20 - Train Acc: 0.7063, Val Acc: 0.7939\n",
      "Current learning rate: 0.000050\n",
      "Epoch 8/20 - Train Acc: 0.6963, Val Acc: 0.8030\n",
      "Current learning rate: 0.000050\n",
      "Epoch 9/20 - Train Acc: 0.7500, Val Acc: 0.8318\n",
      "Current learning rate: 0.000050\n",
      "Epoch 10/20 - Train Acc: 0.7415, Val Acc: 0.8348\n",
      "Current learning rate: 0.000050\n",
      "Epoch 11/20 - Train Acc: 0.7477, Val Acc: 0.8364\n",
      "Current learning rate: 0.000025\n",
      "Epoch 12/20 - Train Acc: 0.7519, Val Acc: 0.8439\n",
      "Current learning rate: 0.000025\n",
      "Epoch 13/20 - Train Acc: 0.7693, Val Acc: 0.8515\n",
      "Current learning rate: 0.000025\n",
      "Epoch 14/20 - Train Acc: 0.7798, Val Acc: 0.8591\n",
      "Current learning rate: 0.000025\n",
      "Epoch 15/20 - Train Acc: 0.7755, Val Acc: 0.8576\n",
      "Current learning rate: 0.000025\n",
      "Epoch 16/20 - Train Acc: 0.7713, Val Acc: 0.8576\n",
      "Current learning rate: 0.000013\n",
      "Epoch 17/20 - Train Acc: 0.7821, Val Acc: 0.8561\n",
      "Current learning rate: 0.000013\n",
      "Epoch 18/20 - Train Acc: 0.7852, Val Acc: 0.8576\n",
      "Current learning rate: 0.000013\n",
      "Epoch 19/20 - Train Acc: 0.7813, Val Acc: 0.8591\n",
      "Current learning rate: 0.000013\n",
      "Epoch 20/20 - Train Acc: 0.7875, Val Acc: 0.8682\n",
      "Current learning rate: 0.000013\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader)\n",
    "    val_loss, val_acc = validate(model, val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Current learning rate: {current_lr:.6f}\")\n",
    "\n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"efficientnet_best.pth\")\n",
    "\n",
    "    # üîÅ Update learning rate\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9ea9eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "         4011       1.00      0.71      0.83        24\n",
      "         4015       0.91      0.88      0.90        49\n",
      "         4088       0.87      0.94      0.91        36\n",
      "         4196       0.96      1.00      0.98        48\n",
      "7020097009819       0.71      1.00      0.83        37\n",
      "7020097026113       1.00      0.54      0.70        13\n",
      "7023026089401       0.95      1.00      0.98        20\n",
      "7035620058776       1.00      0.67      0.80         6\n",
      "7037203626563       1.00      0.20      0.33        10\n",
      "7037206100022       0.82      1.00      0.90        33\n",
      "7038010009457       0.93      1.00      0.97        14\n",
      "7038010013966       0.94      0.88      0.91        33\n",
      "7038010021145       1.00      0.93      0.96        14\n",
      "7038010054488       0.85      0.71      0.77        24\n",
      "7038010068980       0.92      1.00      0.96        33\n",
      "7039610000318       0.89      1.00      0.94        24\n",
      "7040513000022       0.84      0.96      0.90        28\n",
      "7040513001753       1.00      0.73      0.84        11\n",
      "7040913336684       0.92      0.86      0.89        14\n",
      "7044610874661       0.74      0.98      0.84        58\n",
      "7048840205868       1.00      0.43      0.60        14\n",
      "7071688004713       1.00      0.82      0.90        11\n",
      "7622210410337       1.00      0.73      0.85        15\n",
      "     90433917       1.00      0.32      0.48        19\n",
      "     90433924       0.75      0.67      0.71        27\n",
      "        94011       0.83      0.98      0.90        45\n",
      "\n",
      "     accuracy                           0.87       660\n",
      "    macro avg       0.92      0.80      0.83       660\n",
      " weighted avg       0.89      0.87      0.86       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load best model and evaluate\n",
    "model.load_state_dict(torch.load(\"efficientnet_best.pth\"))\n",
    "model.eval()\n",
    "\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(device)\n",
    "        out = model(x)\n",
    "        preds = out.argmax(1).cpu()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(y)\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b22cfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
